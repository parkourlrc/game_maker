{
    "49": {
        "inputs": {
            "images": [
                "118",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "70": {
        "inputs": {
            "motion_model": [
                "71",
                0
            ],
            "scale_multival": [
                "116",
                0
            ]
        },
        "class_type": "ADE_ApplyAnimateDiffModelSimple",
        "_meta": {
            "title": "Apply AnimateDiff Model üé≠üÖêüÖì‚ë°"
        }
    },
    "71": {
        "inputs": {
            "model_name": "v3_sd15_mm.ckpt"
        },
        "class_type": "ADE_LoadAnimateDiffModel",
        "_meta": {
            "title": "Load AnimateDiff Model üé≠üÖêüÖì‚ë°"
        }
    },
    "72": {
        "inputs": {
            "beta_schedule": "sqrt_linear (AnimateDiff)",
            "model": [
                "161",
                0
            ],
            "m_models": [
                "70",
                0
            ],
            "context_options": [
                "73",
                0
            ],
            "sample_settings": [
                "74",
                0
            ]
        },
        "class_type": "ADE_UseEvolvedSampling",
        "_meta": {
            "title": "Use Evolved Sampling üé≠üÖêüÖì‚ë°"
        }
    },
    "73": {
        "inputs": {
            "context_length": 16,
            "context_stride": 1,
            "context_overlap": 4,
            "closed_loop": false,
            "fuse_method": "flat",
            "use_on_equal_length": false,
            "start_percent": 0,
            "guarantee_steps": 1
        },
        "class_type": "ADE_LoopedUniformContextOptions",
        "_meta": {
            "title": "Context Options‚óÜLooped Uniform üé≠üÖêüÖì"
        }
    },
    "74": {
        "inputs": {
            "batch_offset": 0,
            "noise_type": "FreeNoise",
            "seed_gen": "comfy",
            "seed_offset": 0,
            "adapt_denoise_steps": false
        },
        "class_type": "ADE_AnimateDiffSamplingSettings",
        "_meta": {
            "title": "Sample Settings üé≠üÖêüÖì"
        }
    },
    "116": {
        "inputs": {
            "float_val": 1.2
        },
        "class_type": "ADE_MultivalDynamic",
        "_meta": {
            "title": "Multival üé≠üÖêüÖì"
        }
    },
    "118": {
        "inputs": {
            "clamp": true,
            "gamma": 1.1,
            "contrast": 1.1,
            "exposure": 0.15,
            "offset": 0,
            "hue": 0,
            "saturation": 1,
            "value": 1,
            "image": [
                "194",
                0
            ]
        },
        "class_type": "Color Correct (mtb)",
        "_meta": {
            "title": "Color Correct (mtb)"
        }
    },
    "159": {
        "inputs": {
            "preset": "PLUS (high strength)",
            "model": [
                "197",
                0
            ]
        },
        "class_type": "IPAdapterUnifiedLoader",
        "_meta": {
            "title": "IPAdapter Unified Loader"
        }
    },
    "161": {
        "inputs": {
            "weight": 1,
            "weight_type": "linear",
            "combine_embeds": "concat",
            "start_at": 0,
            "end_at": 1,
            "embeds_scaling": "V only",
            "model": [
                "159",
                0
            ],
            "ipadapter": [
                "159",
                1
            ],
            "image": [
                "118",
                0
            ]
        },
        "class_type": "IPAdapterAdvanced",
        "_meta": {
            "title": "IPAdapter Advanced"
        }
    },
    "177": {
        "inputs": {
            "ckpt_name": "zavychromaxl_v80.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "179": {
        "inputs": {
            "lora_name": "sdxl_lightning_8step_lora.safetensors",
            "strength_model": 1,
            "strength_clip": 0,
            "model": [
                "177",
                0
            ],
            "clip": [
                "192",
                0
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Load LoRA"
        }
    },
    "181": {
        "inputs": {
            "width": 560,
            "height": 720,
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "190": {
        "inputs": {
            "text": "a handsome man",
            "clip": [
                "179",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "191": {
        "inputs": {
            "text": "",
            "clip": [
                "179",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "192": {
        "inputs": {
            "stop_at_clip_layer": -1,
            "clip": [
                "177",
                1
            ]
        },
        "class_type": "CLIPSetLastLayer",
        "_meta": {
            "title": "CLIP Set Last Layer"
        }
    },
    "193": {
        "inputs": {
            "seed": [
                "250",
                3
            ],
            "steps": 8,
            "cfg": 1,
            "sampler_name": "euler",
            "scheduler": "sgm_uniform",
            "denoise": 1,
            "model": [
                "179",
                0
            ],
            "positive": [
                "190",
                0
            ],
            "negative": [
                "191",
                0
            ],
            "latent_image": [
                "181",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "194": {
        "inputs": {
            "samples": [
                "193",
                0
            ],
            "vae": [
                "177",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "195": {
        "inputs": {
            "ckpt_name": "juggernaut_reborn.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "196": {
        "inputs": {
            "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "Load VAE"
        }
    },
    "197": {
        "inputs": {
            "lora_name": "AnimateLCM_sd15_t2v_lora.safetensors",
            "strength_model": 1,
            "strength_clip": 0,
            "model": [
                "195",
                0
            ],
            "clip": [
                "198",
                0
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Load LoRA"
        }
    },
    "198": {
        "inputs": {
            "stop_at_clip_layer": -1,
            "clip": [
                "195",
                1
            ]
        },
        "class_type": "CLIPSetLastLayer",
        "_meta": {
            "title": "CLIP Set Last Layer"
        }
    },
    "199": {
        "inputs": {
            "text": "",
            "clip": [
                "197",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "200": {
        "inputs": {
            "text": "",
            "clip": [
                "197",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "201": {
        "inputs": {
            "seed": [
                "250",
                3
            ],
            "steps": 9,
            "cfg": 1,
            "sampler_name": "lcm",
            "scheduler": "sgm_uniform",
            "denoise": 1,
            "model": [
                "72",
                0
            ],
            "positive": [
                "199",
                0
            ],
            "negative": [
                "200",
                0
            ],
            "latent_image": [
                "213",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "203": {
        "inputs": {
            "samples": [
                "201",
                0
            ],
            "vae": [
                "196",
                0
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "213": {
        "inputs": {
            "width": 560,
            "height": 720,
            "batch_size": 24
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "217": {
        "inputs": {
            "model_name": "RealESRGAN_x4.pth"
        },
        "class_type": "UpscaleModelLoader",
        "_meta": {
            "title": "Load Upscale Model"
        }
    },
    "219": {
        "inputs": {
            "upscale_model": [
                "217",
                0
            ],
            "image": [
                "247",
                0
            ]
        },
        "class_type": "ImageUpscaleWithModel",
        "_meta": {
            "title": "Upscale Image (using Model)"
        }
    },
    "220": {
        "inputs": {
            "upscale_method": "nearest-exact",
            "width": 560,
            "height": 720,
            "crop": "disabled",
            "image": [
                "219",
                0
            ]
        },
        "class_type": "ImageScale",
        "_meta": {
            "title": "Upscale Image"
        }
    },
    "223": {
        "inputs": {
            "frame_rate": 30,
            "loop_count": 0,
            "filename_prefix": "interpolated/",
            "format": "video/h264-mp4",
            "pix_fmt": "yuv420p",
            "crf": 15,
            "save_metadata": true,
            "pingpong": false,
            "save_output": true,
            "images": [
                "226",
                0
            ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
            "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
    },
    "224": {
        "inputs": {
            "selected_indexes": "0",
            "images": [
                "220",
                0
            ]
        },
        "class_type": "ImageSelector",
        "_meta": {
            "title": "Image Selector"
        }
    },
    "225": {
        "inputs": {
            "image1": [
                "224",
                0
            ],
            "image2": [
                "220",
                0
            ]
        },
        "class_type": "ImageBatch",
        "_meta": {
            "title": "Batch Images"
        }
    },
    "226": {
        "inputs": {
            "ckpt_name": "rife47.pth",
            "clear_cache_after_n_frames": 320,
            "multiplier": 4,
            "fast_mode": true,
            "ensemble": true,
            "scale_factor": 1,
            "frames": [
                "225",
                0
            ]
        },
        "class_type": "RIFE VFI",
        "_meta": {
            "title": "RIFE VFI (recommend rife47 and rife49)"
        }
    },
    "228": {
        "inputs": {
            "frame_rate": 8,
            "loop_count": 0,
            "filename_prefix": "upscaled/",
            "format": "video/h264-mp4",
            "pix_fmt": "yuv420p",
            "crf": 19,
            "save_metadata": true,
            "pingpong": false,
            "save_output": false,
            "images": [
                "247",
                0
            ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
            "title": "Video Combine üé•üÖ•üÖóüÖ¢"
        }
    },
    "244": {
        "inputs": {
            "upscale_method": "lanczos",
            "scale_by": 2,
            "image": [
                "203",
                0
            ]
        },
        "class_type": "ImageScaleBy",
        "_meta": {
            "title": "Upscale Image By"
        }
    },
    "245": {
        "inputs": {
            "seed": [
                "250",
                3
            ],
            "steps": 10,
            "cfg": 1,
            "sampler_name": "lcm",
            "scheduler": "sgm_uniform",
            "denoise": 0.45,
            "model": [
                "72",
                0
            ],
            "positive": [
                "199",
                0
            ],
            "negative": [
                "200",
                0
            ],
            "latent_image": [
                "246",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "246": {
        "inputs": {
            "pixels": [
                "244",
                0
            ],
            "vae": [
                "196",
                0
            ]
        },
        "class_type": "VAEEncode",
        "_meta": {
            "title": "VAE Encode"
        }
    },
    "247": {
        "inputs": {
            "samples": [
                "245",
                0
            ],
            "vae": [
                "196",
                0
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "250": {
        "inputs": {
            "seed": 27
        },
        "class_type": "Seed",
        "_meta": {
            "title": "Seed"
        }
    }
}